{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import argparse\n",
    "import pickle \n",
    "import os\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caption import caption_image_beam_search, visualize_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO('./data/annotations/captions_flickr30k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = set()\n",
    "for k in coco.anns.keys():\n",
    "    img_ids.add(coco.anns[k]['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for img_id in img_ids:\n",
    "    images.append('data/Flickr30k/flickr30k-images/'+coco.loadImgs(img_id)[0]['file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def main(args, test_images, visualize=False):\n",
    "    \n",
    "    # Load model\n",
    "    checkpoint = torch.load(args['model'])\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder = decoder.to(device)\n",
    "    decoder.eval()\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder = encoder.to(device)\n",
    "    encoder.eval()\n",
    "    \n",
    "    # Load word map (word2idx)\n",
    "    with open(args['word_map'], 'r') as j:\n",
    "        word_map = json.load(j)\n",
    "        \n",
    "    # idx2word\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}  \n",
    "    \n",
    "    for i, image_path in enumerate(test_images):\n",
    "        seq, alphas = caption_image_beam_search(encoder, decoder, image_path, word_map, 4)\n",
    "        \n",
    "        sampled_caption = [rev_word_map[ind] for ind in seq]\n",
    "        sampled_caption = []\n",
    "        for ind in seq[1:]:\n",
    "            word = rev_word_map[ind]\n",
    "            if word == '<end>':\n",
    "                break\n",
    "            sampled_caption.append(word)\n",
    "            \n",
    "        sentence = ' '.join(sampled_caption)\n",
    "        \n",
    "        # Print out the image and the generated caption\n",
    "        print (sentence)\n",
    "        image = Image.open(image_path)\n",
    "        plt.imshow(np.asarray(image))\n",
    "        plt.title(sentence)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "#         plt.savefig('outputs/'+image_path.split('/')[-1])\n",
    "        plt.show()\n",
    "\n",
    "        if visualize:\n",
    "            alphas = torch.FloatTensor(alphas)\n",
    "            visualize_att(image_path, seq, alphas, rev_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model':'./models/BEST_checkpoint_flickr30k_5_cap_per_img_5_min_word_freq.pth.tar',\n",
    "    'word_map':'./models/WORDMAP_flickr30k_5_cap_per_img_5_min_word_freq.json'\n",
    "}\n",
    "test_images = [f'png/test{i}.png' for i in [1,2,3,4,5,6]]\n",
    "main(args, test_images, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model':'./models/BEST_checkpoint_flickr30k_5_cap_per_img_5_min_word_freq.pth.tar',\n",
    "    'word_map':'./models/WORDMAP_flickr30k_5_cap_per_img_5_min_word_freq.json'\n",
    "}\n",
    "test_images = images[10:20]\n",
    "main(args, test_images, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
